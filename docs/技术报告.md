# MetaNote课程视频自动笔记生成系统技术报告

## 1. 项目概述

MetaNote可以帮你把视频搞成笔记。

## 2. 系统架构

1. **ASR模块**：负责将视频中的语音转换为文本（asr_server.py, asr_client.py）
2. **帧提取模块**：从视频中提取潜在关键帧（frame_extractor.py）
3. **图像理解模块**：评估帧的教育价值（image_processor.py）
4. **笔记生成模块**：整合文本和图像，生成结构化笔记（note_generator.py）
5. **主程序和CLI**：处理整体流程和用户交互（main.py, cli.py）

系统工作流程如下：
1. 用户提交视频文件
2. 提取音频并进行语音识别
3. 从视频中提取关键帧候选
4. 使用多模态模型评估帧的价值
5. 整合转录文本和有价值的帧生成笔记
6. 输出Markdown格式的最终笔记

## 3. 关键帧提取技术

### 3.1 提取策略

在`frame_extractor.py`中，系统采用两种主要策略来提取潜在的关键帧：

1. **场景切换检测**：通过比较相邻帧之间的直方图相关性，识别视觉内容发生显著变化的帧
2. **内容稳定性分析**：识别内容保持相对稳定一段时间的帧，通常代表重要的讲解内容

```python
# 场景切换检测
hist_diff = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_CORREL)
if hist_diff < (1 - self.scene_threshold):
    scene_change = True
    # 添加场景切换帧...

# 内容稳定性分析
is_stable = self._check_stability(frames_buffer)
if is_stable and stable_start is None:
    # 处理稳定内容帧...
```

### 3.2 初步评分机制

帧提取器为每个候选帧计算初步分数，基于以下因素：

1. **基础分数**：
   - 场景切换帧：20分
   - 稳定内容帧：15分

2. **复杂度分析加分**：通过`_analyze_complexity`方法进行视觉复杂度评估，最高可加60分。复杂度分析包括：
   - 边缘密度：检测图像中的边缘数量，反映细节丰富程度
   - 图像熵：测量图像的信息量
   - 矩形区域/线条检测：识别教学内容如幻灯片、白板等
   - 表格检测：查找水平和垂直线，识别表格结构
   - 清晰度评估：使用Laplacian算子计算聚焦度

```python
def _analyze_complexity(self, gray: np.ndarray) -> float:
    # 1. 边缘密度分析
    edges = cv2.Canny(gray, 100, 200)
    edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])
    
    # 2. 图像熵计算
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    hist = hist / np.sum(hist)
    hist = hist[hist > 0]
    entropy = -np.sum(hist * np.log2(hist)) if len(hist) > 0 else 0
    
    # 3. 区域分析 - 寻找教学内容区域
    # 4. 表格检测
    # 5. 清晰度评估
    
    # 综合评分计算...
    complexity_score = (
        edge_density * 40 +        # 边缘密度
        entropy * 10 +             # 熵
        min(30, region_score) +    # 区域分析
        table_score +              # 表格检测
        laplacian_score            # 清晰度
    )
    
    return min(60, complexity_score * 0.3)
```

### 3.3 去重和筛选

为避免重复和冗余采用以下策略：

1. **感知哈希去重**：计算帧的感知哈希并比较汉明距离，过滤掉内容非常相似的帧
2. **时间间隔筛选**：确保保留的帧之间有足够的时间间隔（默认2秒）
3. **最低分数阈值**：忽略分数低于25的帧

## 4. 有价值帧的判断核心算法

### 4.1 多模态模型评估

使用多模态AI模型评估帧的教育价值。`image_processor.py`实现了两种方案：

1. **本地Ollama模型**（OllamaProcessor）
2. **云端千问多模态API**（QwenProcessor）

两种方案使用相同的基本逻辑，但与不同的后端交互。

### 4.2 评估提示工程

系统向模型发送以下提示，请求评估图像价值：

```python
def get_default_prompt(self) -> str:
    return (
        "这是一个教学视频中的帧。请评估这个图像是否包含有价值的教学内容"
        "（如幻灯片、图表、代码、公式、重要概念、关键要点），判断是否合适作为笔记的配图。"
        "请简要分析理由，并在回答末尾用[是/否]明确标记你的判断。"
    )
```

这一提示使模型能够：
1. 了解图像的上下文（教学视频）
2. 关注特定类型的内容（幻灯片、图表等）
3. 提供合理的评估理由
4. 给出明确的是/否判断

### 4.3 OllamaProcessor实现细节

本地Ollama处理器使用LLaVA等多模态模型进行评估：

```python
def process_image(self, image_path: str, prompt: Optional[str] = None) -> Dict[str, Any]:
    # 读取并编码图像
    image = cv2.imread(image_path)
    _, buffer = cv2.imencode('.jpg', image)
    img_base64 = base64.b64encode(buffer).decode('utf-8')
    
    # 构造请求
    payload = {
        "model": self.model,
        "prompt": prompt or self.get_default_prompt(),
        "images": [img_base64],
        "stream": False
    }
    
    # 发送请求并解析结果
    response = requests.post(self.url, headers=headers, data=json.dumps(payload))
    result = response.json()
    response_text = result.get('response', '')
    
    # 解析判断结果
    is_valuable = '[是]' in response_text or response_text.strip().endswith('是')
    score = 75 if is_valuable else 25
    
    # 提取描述（移除判断部分）
    description = response_text
    if '[是]' in description:
        description = description.replace('[是]', '').strip()
    # 其他处理...
    
    return {
        'is_valuable': is_valuable,
        'description': description,
        'score': score,
        'reason': response_text
    }
```

### 4.4 QwenProcessor实现细节

千问处理器使用阿里云的多模态API：

```python
def process_image(self, image_path: str, prompt: Optional[str] = None) -> Dict[str, Any]:
    # 编码图像
    image_b64 = self._encode_image(image_path)
    
    # 构建请求
    completion = self.client.chat.completions.create(
        model=self.model,
        messages=[
            {"role": "user", "content": [
                {"type": "text", "text": prompt or self.get_default_prompt()},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
            ]}
        ]
    )
    
    # 处理响应
    response_text = completion.choices[0].message.content
    
    # 解析判断和描述...
    
    return {
        'is_valuable': is_valuable,
        'description': description,
        'score': 75 if is_valuable else 25,
        'reason': response_text
    }
```

### 4.5 并行处理

为提高效率，系统实现了并行处理多个图像的功能：

```python
def process_images(self, image_paths: List[str], prompt: Optional[str] = None) -> List[Dict[str, Any]]:
    # 使用线程池并行处理
    with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
        # 提交所有任务
        future_to_path = {
            executor.submit(self.process_image, path, prompt): path 
            for path in image_paths if self._is_image_file(path)
        }
        
        # 收集结果...
```

### 4.6 标记有价值帧

评估完成后，系统更新FrameExtractor中的帧信息，标记有价值的帧：

```python
def update_frame_value(self, frame_id: int, is_valuable: bool, description: str = "") -> None:
    # 更新候选帧列表
    for frame in self.candidate_frames:
        if frame['id'] == frame_id:
            frame['is_valuable'] = is_valuable
            frame['content_description'] = description
            
            # 如果有价值，复制到valuable_frames目录
            if is_valuable:
                src_path = os.path.join(self.frames_dir, frame['filename'])
                dst_path = os.path.join(self.valuable_frames_dir, frame['filename'])
                shutil.copy2(src_path, dst_path)
            break
```

## 5. 笔记生成流程

### 5.1 QwenNoteGenerator实现

```python
def generate_notes(self, transcript: str, frames_info: List[Dict[str, Any]], output_path: str, title: Optional[str] = None, summary: Optional[str] = None) -> str:
    # 预处理转录文本和帧信息
    # ...
    
    # 构造提示文本
    prompt = f"""我需要你根据以下视频转录文本和关键帧信息，生成一份专业、详细的学术Markdown笔记。
    
    ## 视频标题
    {title or "未命名课程"}
    
    ## 视频转录文本
    {transcript_text}
    
    ## 关键帧信息
    {frames_text}
    
    请生成一份完整且专业的Markdown笔记，要求如下：
    ...
    """
    
    # 调用千问API生成笔记
    completion = self.client.chat.completions.create(
        model=self.model,
        messages=[
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": prompt}
        ]
    )
    
    # 保存笔记...
```

### 5.2 备用基础笔记生成器

系统还提供了一个基础的笔记生成备选方案，用于API调用失败的情况：

```python
def _generate_basic_notes(self, transcript: str, frames_info: List[Dict[str, Any]], output_path: str, title: Optional[str] = None, summary: Optional[str] = None) -> str:
    # 获取模板
    template = self._get_template()
    
    # 提取或生成标题和摘要
    # ...
    
    # 提取关键概念
    key_concepts = self._extract_key_concepts(transcript)
    
    # 提取可能的章节
    sections = self._extract_possible_sections(transcript)
    
    # 基于章节时间结构，将图像分配到相应章节
    # ...
    
    # 填充模板生成笔记
    # ...
```

## 6. 系统评估与性能

### 6.1 有价值帧判断的准确性

系统通过多层次判断策略提高准确性：

1. **第一层**：帧提取器基于视觉特征提取潜在关键帧
2. **第二层**：多模态模型评估帧的教育价值
3. **结果验证**：生成HTML报告，便于人工验证和质量控制

### 6.2 效率优化

1. **并行处理**：使用ThreadPoolExecutor并行处理多个图像
2. **分级评估**：先进行初步筛选，再进行深度理解
3. **图像去重**：使用感知哈希减少冗余处理
4. **分辨率优化**：处理适当大小的图像以平衡质量和速度

### 6.3 资源消耗

1. **ASR模型**：语音识别需要较高计算资源
2. **多模态模型**：图像理解是最消耗资源的部分
3. **临时存储**：处理过程中生成的中间文件

## 7. 结论与未来改进

### 7.1 主要创新点

1. **多级关键帧提取策略**：结合场景变化和内容稳定性
2. **复杂度分析评分机制**：针对教学内容的特点设计
3. **多模态模型判断**：使用AI理解图像教育价值
4. **灵活模块化设计**：支持本地或云端处理

### 7.2 局限性

1. **依赖模型质量**：判断准确性受限于底层模型能力。在现在的测试中，两个方案的模型效果都有待加强。
2. **计算资源要求**：完整流程需要较高计算资源
3. **特定领域适应性**：对非传统教学内容效果可能有限

## 8. 参考文献

1. OpenCV文档: https://docs.opencv.org/
2. 千问多模态模型文档: https://dashscope.aliyun.com/
3. FunASR语音识别系统: https://github.com/alibaba-damo-academy/FunASR
4. Ollama本地模型: https://github.com/ollama/ollama